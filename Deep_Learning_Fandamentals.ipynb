{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMj4V+IRcKr+/EATJmlsFwl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muhammadalinoor-1982/Blog/blob/master/Deep_Learning_Fandamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Neuron ?**\n",
        "\n",
        "A neuron is a unit in a neural network that **`computes a weighted sum of inputs, adds a bias, and applies an activation function`** to produce an output, simulating decision-making processes."
      ],
      "metadata": {
        "id": "sepksZkv00Ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is weight ?**\n",
        "\n",
        "**A weight is a `trainable parameter` that determines the `strength and importance` of a `connection between neurons`.**"
      ],
      "metadata": {
        "id": "AbEQhZCI-HEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Hidden Layer ?**\n",
        "\n",
        "**A hidden layer is an `intermediate layer of neurons` that `receives inputs from the previous layer`, applies weights, biases, and activation functions, and `passes the transformed outputs to the next layer`, enabling `feature extraction and pattern learning.`**"
      ],
      "metadata": {
        "id": "kNO7Rcx6AdRb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Forward Propagation ?**\n",
        "\n",
        "**Forward propagation is the `sequential process` where `input data is passed through each layer of a neural network,` with neurons computing weighted sums of inputs, adding biases, applying activation functions, and producing outputs that flow to the next layer until the final prediction is obtained.**"
      ],
      "metadata": {
        "id": "AaNYfNLZEKwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Back Propagation ?**\n",
        "\n",
        "**Backpropagation is the process of computing the `gradient of the loss function` with respect to the network's weights and biases by `propagating the error backward through the layers.` It is used to `update the weights via optimization algorithms` like gradient descent to `minimize the loss`.**"
      ],
      "metadata": {
        "id": "9fW90vknI9hp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Memoization ?**\n",
        "\n",
        "**Memoization is an `optimization technique` where `intermediate computational results are cached and reused to avoid redundant calculations,` often applied in dynamic programming or recursive algorithms rather than directly in neural network operations.**"
      ],
      "metadata": {
        "id": "LaGg7iMghD5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**How to find Unique word ?**\n",
        "\n",
        "**Filter Unique words in three steps**\n",
        "\n",
        "**`Step #01: Tokenization`**\n",
        "\n",
        "Split the text into individal words or token using method like witespace spliting, regex, NLTK, SpeCy, or Hugging Face\n",
        "\n",
        "**`Step #02: Remove Duplicates`**\n",
        "\n",
        "Convert the tokenized list into a set to eliminate duplicates using set() function.\n",
        "\n",
        "**`Step #03: Remove Stopwords`**\n",
        "\n",
        "Use stemming/lemmatization to remove stopwords and punctuation.\n",
        "\n",
        "___________________________________________________\n",
        "\n",
        "Unique words are often part of creating a vocabulary, used in techniques like word embeddings (e.g., Word2Vec, GloVe) or tokenization for models like transformers."
      ],
      "metadata": {
        "id": "zF8GcsKVrIj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Activation Function ?**\n",
        "\n",
        "An activation function is a **`mathematical function applied to the weighted sum of inputs and bias in a neuron to introduce non-linearity`**, ensuring the neural network can learn and represent complex patterns beyond linear relationships."
      ],
      "metadata": {
        "id": "3dbebFhsOg61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Dead Activation ?**\n",
        "\n",
        "Dead activation occurs **`when a neuron consistently outputs zero due to the activation function`**, making it unresponsive to input variations. This commonly happens with **`the ReLU activation function when the weighted sum of inputs is negative, causing gradients to be zero, preventing weight updates, and effectively deactivating the neuron during training.`**"
      ],
      "metadata": {
        "id": "IY3orvwhST5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is TanH ?**\n",
        "\n",
        "The TanH (hyperbolic tangent) activation function is a **`non-linear function that transforms input values into a range between -1 and 1,`** helping to center data around zero, which improves training stability. It is defined as:\n",
        "\n",
        "![TanH.PNG](data:image/png;base64,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)\n",
        "\n",
        "Unlike the Sigmoid function (which ranges from 0 to 1), **`TanH reduces the risk of vanishing gradients`** by allowing both positive and negative activations, making it more effective in hidden layers."
      ],
      "metadata": {
        "id": "XT_33x64W56I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Sigmoid ?**\n",
        "\n",
        "The Sigmoid activation function is a **`non-linear function (S-shaped)`** that maps input values to a **`range between 0 and 1,`** making it useful for probabilistic predictions. It is defined as:\n",
        "\n",
        "![Sigmoid.PNG](data:image/png;base64,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)\n",
        "\n",
        "It is commonly **`used in binary classification`** problems but can **`suffer from vanishing gradients (output not centered around zero),`** making it less effective (**`slow down training`**) in deep networks compared to ReLU or TanH."
      ],
      "metadata": {
        "id": "n2EpGUOxWVT1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is ReLU ?**\n",
        "\n",
        "The ReLU (Rectified Linear Unit) activation function is a **`non-linear function`** that outputs the input directly if **`it is positive`**; otherwise, it **`returns zero`**. It is defined as:\n",
        "\n",
        "![ReLU.PNG](data:image/png;base64,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)\n",
        "\n",
        "**`ReLU is widely used in hidden layers`** of deep neural networks because it helps **`mitigate the vanishing gradient`** problem, accelerates training, and introduces sparsity. However, **`it can suffer from the dying ReLU problem, where neurons output zero permanently`** if they receive only negative inputs."
      ],
      "metadata": {
        "id": "XtCWC8qhjQB7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Leaky ReLU ?**\n",
        "\n",
        "Leaky ReLU (Leaky Rectified Linear Unit) is an **`improved version of ReLU`** that **`allows small negative values`** instead of zero for negative inputs, **`preventing dead neurons`**. It is defined as:\n",
        "\n",
        "![Leaky ReLU.PNG](data:image/png;base64,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)\n",
        "\n",
        "where **`α (a small positive constant, e.g., 0.01) controls the slope for negative values.`** This helps **`mitigate the dying ReLU problem`**, improving gradient flow during training."
      ],
      "metadata": {
        "id": "ePyrvxh7pze3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is SoftMax ?**\n",
        "\n",
        "The SoftMax activation function **`transforms a vector of raw scores (logits)`** into a probability distribution, making it **`suitable for multi-class classification.`** It is defined as:\n",
        "\n",
        "![SoftMax.PNG](data:image/png;base64,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)\n",
        "\n",
        "where **`xi`** is the **`i-th`** input, and the denominator sums the exponentials of all inputs.\n",
        "\n",
        "**Key properties:**\n",
        "\n",
        "&#10687; **`Converts outputs into probabilities, where each value is between 0 and 1.`**\n",
        "\n",
        "&#10687; Ensures the sum of all outputs equals 1, allowing interpretation as class probabilities.\n",
        "\n",
        "&#10687; **`Highlights the largest value while still considering smaller ones`**, improving model decision-making in classification tasks."
      ],
      "metadata": {
        "id": "l2nAhXjsu-oA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Batch Gradiant Decent ?**\n",
        "\n",
        "Batch Gradient Descent is an optimization algorithm that **`updates model parameters by computing the gradient of the loss function`** using the entire training dataset **`in each iteration.`** The weight update rule is:\n",
        "\n",
        "![Batch Gradiant Decent.PNG](data:image/png;base64,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)\n",
        "\n",
        "where:\n",
        "\n",
        "\n",
        "W = model parameters (weights)\n",
        "\n",
        "η = learning rate\n",
        "\n",
        "∇L(W) = gradient of the loss function\n",
        "\n",
        "**Key properties:**\n",
        "\n",
        "&#10687; Uses the full dataset for each update, leading to stable but slow convergence.\n",
        "\n",
        "&#10687; Computationally expensive for large datasets.\n",
        "\n",
        "&#10687; More suitable for convex or small-scale problems but less efficient for deep learning compared to Stochastic Gradient Descent (SGD) or Mini-Batch Gradient Descent.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-S2Vt9BN1XSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Mini Batch Gradiant Decent ?**\n",
        "\n",
        "Mini-Batch Gradient Descent is an optimization algorithm that **`updates model parameters`** by computing the gradient of the loss function using a **`small subset (mini-batch)`** of the training data in each iteration.\n",
        "\n",
        "![download.png](data:image/png;base64,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)\n",
        "\n",
        "**Key properties:**\n",
        "\n",
        "&#10687; Balances between Batch Gradient Descent **`(stable but slow)`** and Stochastic Gradient Descent (SGD) **`(fast but noisy)`**.\n",
        "\n",
        "&#10687; **`Reduces computation time`** compared to full-batch updates while maintaining **`smoother convergence than SGD.`**\n",
        "\n",
        "&#10687; Commonly used in deep learning due to its efficiency and ability to leverage vectorized operations in GPUs."
      ],
      "metadata": {
        "id": "emdCusirl7w7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**What is Stochestic Gradiant Decent ?**\n",
        "\n",
        "Stochastic Gradient Descent (SGD) is **`updates model parameters`** by computing the gradient of the loss function using a **`single randomly selected data point in each iteration.`** The update rule is:\n",
        "\n",
        "![SGD.PNG](data:image/png;base64,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)\n",
        "\n",
        "**Key properties:**\n",
        "\n",
        "&#10687; Faster updates compared to Batch Gradient Descent, making it **`suitable for large datasets.`**\n",
        "\n",
        "&#10687; **`Introduces randomness,`** leading to high variance in updates, which can help **`escape local minima`** but may cause instability.\n",
        "\n",
        "&#10687; Typically combined with techniques like **`learning rate decay or momentum`** to improve convergence stability."
      ],
      "metadata": {
        "id": "VuS_RWRSsv4w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yzRA9YUV1hLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}